{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7becb0b4",
   "metadata": {},
   "source": [
    "**Loading image data with a custom Dataset:**\t\n",
    "\n",
    "What if PyTorch didn't have an in-built function to load data with? This is where we can build our own custom subclass of `torch.utils.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfbb5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use datasets as per the need of problem we are trying to solve. \n",
    "# In pytorch, we need to use dataset that inherits original Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed3436cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import zipfile  \n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e580d5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find data/pizza_steak_sushi directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Unzipping pizza, steak, sushi data...\n"
     ]
    }
   ],
   "source": [
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it... \n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists.\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading pizza, steak, sushi data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping pizza, steak, sushi data...\") \n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf8ffd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c5fab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target directory: data/pizza_steak_sushi/train\n",
      "Class names found: ['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "# Setup path for target directory\n",
    "target_directory = train_dir\n",
    "print(f\"Target directory: {target_directory}\")\n",
    "\n",
    "# Get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(image_path / \"train\"))])\n",
    "print(f\"Class names found: {class_names_found}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23e6921",
   "metadata": {},
   "source": [
    "***Making a function***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93037eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "    \n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\")\n",
    "        >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "    \n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}.\")\n",
    "        \n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84553400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['pizza', 'steak', 'sushi'], {'pizza': 0, 'steak': 1, 'sushi': 2})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_classes(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c614c118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['pizza', 'steak', 'sushi'], {'pizza': 0, 'steak': 1, 'sushi': 2})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_classes(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb3f303",
   "metadata": {},
   "source": [
    "### Create a custom Dataset to replicate ImageFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb4a195",
   "metadata": {},
   "source": [
    "1. Subclass torch.utils.data.Dataset.\n",
    "2. Initialize our subclass with a targ_dir parameter (the target data directory) and transform parameter (so we have the option to transform our data if needed).\n",
    "3. Create several attributes for paths (the paths of our target images), transform (the transforms we might like to use, this can be None), classes and class_to_idx (from our find_classes() function).\n",
    "4. Create a function to load images from file and return them, this could be using PIL or torchvision.io (for input/output of vision data).\n",
    "5. Overwrite the __len__ method of torch.utils.data.Dataset to return the number of samples in the Dataset, this is recommended but not required. This is so you can call len(Dataset).\n",
    "6. Overwrite the __getitem__ method of torch.utils.data.Dataset to return a single sample from the Dataset, this is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f379a372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    \n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        \n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\")) # note: you'd have to update this if you've got .png's or .jpeg's\n",
    "        # Setup transforms\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path) \n",
    "    \n",
    "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "    \n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        class_name  = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpeg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa05d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment train data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Don't augment test data, only reshape\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1e177c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<__main__.ImageFolderCustom at 0x7fb1d2a9cf10>,\n",
       " <__main__.ImageFolderCustom at 0x7fb1d2a9db40>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_custom = ImageFolderCustom(targ_dir=train_dir, \n",
    "                                      transform=train_transforms)\n",
    "test_data_custom = ImageFolderCustom(targ_dir=test_dir, \n",
    "                                     transform=test_transforms)\n",
    "train_data_custom, test_data_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4e3c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 75)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data_custom), len(test_data_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5980b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pizza': 0, 'steak': 1, 'sushi': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_custom.class_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b149c064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pizza', 'steak', 'sushi']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_custom.classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118fa32",
   "metadata": {},
   "source": [
    "### Into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b52c4662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7fb1d2aafa30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7fb1d2a9cb80>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn train and test custom Dataset's into DataLoader's\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader_custom = DataLoader(dataset=train_data_custom, # use custom created train Dataset\n",
    "                                     batch_size=1, # how many samples per batch?\n",
    "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more computation)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader_custom = DataLoader(dataset=test_data_custom, # use custom created test Dataset\n",
    "                                    batch_size=1, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4e0d69",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "**[For More Info](https://www.learnpytorch.io/04_pytorch_custom_datasets/)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72777ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
